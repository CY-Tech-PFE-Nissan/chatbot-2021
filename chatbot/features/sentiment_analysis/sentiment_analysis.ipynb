{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"892f772d81e1439b822d6d35ae61e2e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a68764c8b5f14548a4492160a8b6f4fc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d5223e14b2dc4ea2806835f9af3ee9ca","IPY_MODEL_cebb25c7f62e423899c2d651bb65c704"]}},"a68764c8b5f14548a4492160a8b6f4fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5223e14b2dc4ea2806835f9af3ee9ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8102c33537b14180a8ba2e0ff09707e7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f27e4802fe3491082f4a139f72872a4"}},"cebb25c7f62e423899c2d651bb65c704":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fc2476c6901e404aa1fbb84da33d2ab2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.33MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_037d1af04598470ab5c143da085a7a6d"}},"8102c33537b14180a8ba2e0ff09707e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3f27e4802fe3491082f4a139f72872a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc2476c6901e404aa1fbb84da33d2ab2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"037d1af04598470ab5c143da085a7a6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59914d54096f4259a49098f32558f7fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c20dc338fa049a38ceac97f3600bb3d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bd4c52e045554a6493b04fd755cf2063","IPY_MODEL_2751ae6028f944bfa73ed0bfda5757c6"]}},"4c20dc338fa049a38ceac97f3600bb3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd4c52e045554a6493b04fd755cf2063":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9737300a4bea46669ab499eb9fbde07d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b608fa63f44542d094d648d0d2bf3c64"}},"2751ae6028f944bfa73ed0bfda5757c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_846eff2364254b5895b49c1b68b3dc7b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 2.33kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_259b3237302a440cb3702e99d6cfd51f"}},"9737300a4bea46669ab499eb9fbde07d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b608fa63f44542d094d648d0d2bf3c64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"846eff2364254b5895b49c1b68b3dc7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"259b3237302a440cb3702e99d6cfd51f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"037b518a91654c099665d98ed7ec4098":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d7425588f8464bdba96dbbf3978ebdce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_834d66202a12411fa3b0d8eeb8743dde","IPY_MODEL_b9ccee12334c4685a50315901f2facb5"]}},"d7425588f8464bdba96dbbf3978ebdce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"834d66202a12411fa3b0d8eeb8743dde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea06f3bda3e3421596a731228bd25683","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_381477d6b5904720b134c0679b738ce3"}},"b9ccee12334c4685a50315901f2facb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1565f5a09d7646db811a865d19b9d4c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:06&lt;00:00, 73.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8210ef402834b22813b980d90ca14a7"}},"ea06f3bda3e3421596a731228bd25683":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"381477d6b5904720b134c0679b738ce3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1565f5a09d7646db811a865d19b9d4c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f8210ef402834b22813b980d90ca14a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"v2TYyAzjCGts"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3dXqF1KLhOF","executionInfo":{"status":"ok","timestamp":1612448329434,"user_tz":-60,"elapsed":2652,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"55d2a028-5055-417e-f2f4-88ed8285d506"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AfwSo7aXAPvP"},"source":["import csv\n","import torch\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YEAlG-rzDC9G"},"source":["device = torch.device('cuda' if torch.cuda.is_available()\n","else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OjBRd8-kCRce"},"source":["# Download Data\n","\n","Dataset is based on [MELD](https://github.com/declare-lab/MELD). We will only keep utterances and sentiment, i.e. have each row like :\n","\n","* [\"Oh my God, he’s lost it. He’s totally lost it.\", \"negative\"]\n","* [\"Or! Or, we could go to the bank, close our accounts and cut them off at the source.\",  \"neutral\"]\n","* [\"You’re a genius!\", \"positive\"]"]},{"cell_type":"code","metadata":{"id":"U5on2AbgDLcs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612448329438,"user_tz":-60,"elapsed":2620,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"eae47fe8-0214-4271-e199-29ff980174b4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wZxhnzkVQFbq"},"source":["data_folder = \"/content/drive/Shareddrives/PFE ING3 IA NISSAN/Ressources/sentiment_analysis/data/\"\n","\n","datasets = {\n","    x: {'sentences': [], 'labels': [], 'input_ids': [], 'attention_masks': []} for x in ['train', 'dev', 'test']\n","}\n","\n","label_names = ['positive','negative','neutral']\n","\n","def define_label(label):\n","    if label == 'positive':\n","        return 0\n","    elif label == 'negative':\n","        return 1\n","    else:\n","        return 2\n","\n","with open(data_folder + \"train.csv\", 'r') as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=\",\")\n","    for row in csv_reader:\n","        datasets['train']['sentences'].append(row[0])\n","        datasets['train']['labels'].append(define_label(row[1]))\n","\n","with open(data_folder + \"dev.csv\", 'r') as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=\",\")\n","    for row in csv_reader:\n","        datasets['dev']['sentences'].append(row[0])\n","        datasets['dev']['labels'].append(define_label(row[1]))\n","                                      \n","with open(data_folder + \"test.csv\", 'r') as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=\",\")\n","    for row in csv_reader:\n","        datasets['test']['sentences'].append(row[0])\n","        datasets['test']['labels'].append(define_label(row[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b6OPJ4g0aPqr"},"source":["# Tokenization and input formatting"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":82,"referenced_widgets":["892f772d81e1439b822d6d35ae61e2e0","a68764c8b5f14548a4492160a8b6f4fc","d5223e14b2dc4ea2806835f9af3ee9ca","cebb25c7f62e423899c2d651bb65c704","8102c33537b14180a8ba2e0ff09707e7","3f27e4802fe3491082f4a139f72872a4","fc2476c6901e404aa1fbb84da33d2ab2","037d1af04598470ab5c143da085a7a6d"]},"id":"cfr4mU9uSM-Q","executionInfo":{"status":"ok","timestamp":1612448334971,"user_tz":-60,"elapsed":8133,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"296251b5-100b-49dc-ab90-451dd74a1613"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","max_len = 0\n","\n","for sent in datasets['train']['sentences']:\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"892f772d81e1439b822d6d35ae61e2e0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Max sentence length:  95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZNZogcCUUSC","executionInfo":{"status":"ok","timestamp":1612448339194,"user_tz":-60,"elapsed":12348,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"30d76db5-51a0-409b-f31d-6447829c35e5"},"source":["# Tokenize all of the sentences and map the tokens to their word IDs.\n","for data in ['train', 'dev', 'test']:\n","\n","    for sent in datasets[data]['sentences']:\n","        # `encode_plus` will:\n","        #   (1) Tokenize the sentence.\n","        #   (2) Prepend the `[CLS]` token to the start.\n","        #   (3) Append the `[SEP]` token to the end.\n","        #   (4) Map tokens to their IDs.\n","        #   (5) Pad or truncate the sentence to `max_length`\n","        #   (6) Create attention masks for [PAD] tokens.\n","        encoded_dict = tokenizer.encode_plus(\n","                            sent,                      # Sentence to encode.\n","                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                            max_length = max_len,           # Pad & truncate all sentences.\n","                            pad_to_max_length = True,\n","                            return_attention_mask = True,   # Construct attn. masks.\n","                            return_tensors = 'pt',     # Return pytorch tensors.\n","                      )\n","        \n","        # Add the encoded sentence to the list.    \n","        datasets[data]['input_ids'].append(encoded_dict['input_ids'])\n","        \n","        # And its attention mask (simply differentiates padding from non-padding).\n","        datasets[data]['attention_masks'].append(encoded_dict['attention_mask'])\n","\n","    # Convert the lists into tensors.\n","    datasets[data]['input_ids'] = torch.cat(datasets[data]['input_ids'], dim=0)\n","    datasets[data]['attention_masks'] = torch.cat(datasets[data]['attention_masks'], dim=0)\n","    datasets[data]['labels'] = torch.tensor(datasets[data]['labels'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8NTMrxZYGnz","executionInfo":{"status":"ok","timestamp":1612448339197,"user_tz":-60,"elapsed":12343,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"da27e82f-93e5-474c-dfd3-b67e8c64e975"},"source":["# Print sentence 0, now as a list of IDs.\n","print('Original: ', datasets['train']['sentences'][0])\n","print('Token IDs:', datasets['train']['input_ids'][0])\n","print('Attention mask:', datasets['train']['attention_masks'][0])\n","print('Label:', datasets['train']['labels'][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  also I was the point person on my company’s transition from the KL-5 to GR-6 system.\n","Token IDs: tensor([  101,  2036,  1045,  2001,  1996,  2391,  2711,  2006,  2026,  2194,\n","         1521,  1055,  6653,  2013,  1996,  1047,  2140,  1011,  1019,  2000,\n","        24665,  1011,  1020,  2291,  1012,   102,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0])\n","Attention mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","Label: tensor(2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jz59By3ge--0"},"source":["# Combine the inputs into a TensorDataset.\n","train_dataset = TensorDataset(datasets['train']['input_ids'], datasets['train']['attention_masks'], datasets['train']['labels'])\n","validation_dataset = TensorDataset(datasets['dev']['input_ids'], datasets['dev']['attention_masks'], datasets['dev']['labels'])\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            validation_dataset, # The validation samples.\n","            sampler = SequentialSampler(validation_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"63a4Y7ZdCa8G"},"source":["# Model definition\n","\n","Our model is based on BERT, applied to sentiment classification."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["59914d54096f4259a49098f32558f7fe","4c20dc338fa049a38ceac97f3600bb3d","bd4c52e045554a6493b04fd755cf2063","2751ae6028f944bfa73ed0bfda5757c6","9737300a4bea46669ab499eb9fbde07d","b608fa63f44542d094d648d0d2bf3c64","846eff2364254b5895b49c1b68b3dc7b","259b3237302a440cb3702e99d6cfd51f","037b518a91654c099665d98ed7ec4098","d7425588f8464bdba96dbbf3978ebdce","834d66202a12411fa3b0d8eeb8743dde","b9ccee12334c4685a50315901f2facb5","ea06f3bda3e3421596a731228bd25683","381477d6b5904720b134c0679b738ce3","1565f5a09d7646db811a865d19b9d4c3","f8210ef402834b22813b980d90ca14a7"]},"id":"_MNV8-AciIw3","executionInfo":{"status":"ok","timestamp":1612448358672,"user_tz":-60,"elapsed":31802,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"a7b2b96d-efbb-41d4-8709-d7fa670359d8"},"source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 3, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59914d54096f4259a49098f32558f7fe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"037b518a91654c099665d98ed7ec4098","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"jAvWEE9-oskE"},"source":["# Freeze all layers\n","#for param in model.parameters():\n","#    param.requires_grad = False\n","\n","#model.bert.encoder.layer[10:12].requires_grad = True\n","#model.bert.pooler.requires_grad = True\n","#model.classifier.requires_grad = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AT6czoTBjQ1W"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 1e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4DWxjyroCq4U"},"source":["# Training model"]},{"cell_type":"code","metadata":{"id":"f3M9i-hBkkYq"},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","  \n","# Function for formatting elapsed time as hh::mm::ss\n","def format_time(elapsed):\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZpjiNegplrze","executionInfo":{"status":"ok","timestamp":1612448684694,"user_tz":-60,"elapsed":357789,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"a014e03d-d8d6-4de6-e223-d188b1536451"},"source":["# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","#seed_val = 99\n","\n","#random.seed(seed_val)\n","#np.random.seed(seed_val)\n","#torch.manual_seed(seed_val)\n","#torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        outputs = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += outputs.loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        outputs.loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            outputs = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += outputs.loss.item()\n","\n","        # Move logits and labels to CPU\n","        outputs.logits = outputs.logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(outputs.logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","  Batch    40  of    313.    Elapsed: 0:00:19.\n","  Batch    80  of    313.    Elapsed: 0:00:38.\n","  Batch   120  of    313.    Elapsed: 0:00:58.\n","  Batch   160  of    313.    Elapsed: 0:01:17.\n","  Batch   200  of    313.    Elapsed: 0:01:37.\n","  Batch   240  of    313.    Elapsed: 0:01:57.\n","  Batch   280  of    313.    Elapsed: 0:02:17.\n","\n","  Average training loss: 0.86\n","  Training epoch took: 0:02:34\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation Loss: 0.77\n","  Validation took: 0:00:06\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","  Batch    40  of    313.    Elapsed: 0:00:20.\n","  Batch    80  of    313.    Elapsed: 0:00:41.\n","  Batch   120  of    313.    Elapsed: 0:01:01.\n","  Batch   160  of    313.    Elapsed: 0:01:22.\n","  Batch   200  of    313.    Elapsed: 0:01:42.\n","  Batch   240  of    313.    Elapsed: 0:02:03.\n","  Batch   280  of    313.    Elapsed: 0:02:23.\n","\n","  Average training loss: 0.71\n","  Training epoch took: 0:02:40\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation Loss: 0.76\n","  Validation took: 0:00:06\n","\n","Training complete!\n","Total training took 0:05:26 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"32e8eEOfCtM7"},"source":["# Performances"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"6EZEZp5AyLRc","executionInfo":{"status":"ok","timestamp":1612448684701,"user_tz":-60,"elapsed":357788,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"3094cac1-f51e-41fe-dfb7-6967665ed3c8"},"source":["# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df_stats = df_stats.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.86</td>\n","      <td>0.77</td>\n","      <td>0.67</td>\n","      <td>0:02:34</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.71</td>\n","      <td>0.76</td>\n","      <td>0.68</td>\n","      <td>0:02:40</td>\n","      <td>0:00:06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.86         0.77           0.67       0:02:34         0:00:06\n","2               0.71         0.76           0.68       0:02:40         0:00:06"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"PxfLaNvcy_Ou","executionInfo":{"status":"ok","timestamp":1612448685029,"user_tz":-60,"elapsed":358108,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"b9f8f267-f393-4d01-e68a-37adae456d0b"},"source":["# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"UFFXY2GYzSNI"},"source":["# Evaluation on Test set"]},{"cell_type":"code","metadata":{"id":"3akT7oyke8aj"},"source":["test_dataset = TensorDataset(datasets['test']['input_ids'], datasets['test']['attention_masks'], datasets['test']['labels'])\n","\n","test_dataloader = DataLoader(\n","            test_dataset, \n","            sampler = SequentialSampler(test_dataset),\n","            batch_size = batch_size \n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhCZ55oTfY5K"},"source":["model.eval()\n","\n","total_test_accuracy = 0\n","for batch in test_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","  b_input_ids, b_input_mask, b_labels = batch\n","\n","  with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  outputs.logits = outputs.logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  total_test_accuracy += flat_accuracy(outputs.logits, label_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3j4zpQTZDGL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612449575724,"user_tz":-60,"elapsed":413,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"8279664e-d41d-45d3-caa5-56bba28416b0"},"source":["avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n","print(\"  Accuracy: {0:.2f}\".format(avg_test_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Accuracy: 0.71\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q-G_5Rw7Cxlo"},"source":["# Save model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNNqW3GufJWJ","executionInfo":{"status":"ok","timestamp":1612450137409,"user_tz":-60,"elapsed":2462,"user":{"displayName":"Adrien Lapeyre","photoUrl":"","userId":"03466639933529886837"}},"outputId":"eead777c-7242-4f77-8004-b867c3e76cc1"},"source":["import os\n","\n","output_dir = \"/content/drive/Shareddrives/PFE ING3 IA NISSAN/Ressources/sentiment_analysis/model\"\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to /content/drive/Shareddrives/PFE ING3 IA NISSAN/Ressources/sentiment_analysis/model\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/Shareddrives/PFE ING3 IA NISSAN/Ressources/sentiment_analysis/model/tokenizer_config.json',\n"," '/content/drive/Shareddrives/PFE ING3 IA NISSAN/Ressources/sentiment_analysis/model/special_tokens_map.json',\n"," '/content/drive/Shareddrives/PFE ING3 IA NISSAN/Ressources/sentiment_analysis/model/vocab.txt',\n"," '/content/drive/Shareddrives/PFE ING3 IA NISSAN/Ressources/sentiment_analysis/model/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":37}]}]}